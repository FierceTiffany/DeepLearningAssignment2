{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2hde6L-32Aw",
        "outputId": "b3883c8a-1159-4225-af04-4093263d1e64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QOFT_--4DZj",
        "outputId": "8c19aec8-abfe-4549-ab1f-c1ba5cd94f64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/112_2_DL\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['images', 'Assignment2_Q1.ipynb', 'Assignment2_Q2.ipynb']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/112_2_DL\"\n",
        "import os\n",
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U2T19xVG4IId"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HINaU20X4PwN"
      },
      "outputs": [],
      "source": [
        "train_set = pd.read_csv(\"images/train.txt\", sep=\" \", header=None)\n",
        "valid_set = pd.read_csv(\"images/val.txt\", sep=\" \", header=None)\n",
        "test_set = pd.read_csv(\"images/test.txt\", sep=\" \", header = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "XYopP7vz4Rl8",
        "outputId": "49a4b961-38f1-4172-a132-2bd19e6503e6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>images/n02111277/n02111277_10005.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>images/n02111277/n02111277_10019.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>images/n02111277/n02111277_10072.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>images/n02111277/n02111277_1008.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>images/n02111277/n02111277_10089.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63320</th>\n",
              "      <td>images/n02172182/n02172182_9515.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63321</th>\n",
              "      <td>images/n02172182/n02172182_954.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63322</th>\n",
              "      <td>images/n02172182/n02172182_9549.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63323</th>\n",
              "      <td>images/n02172182/n02172182_9589.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63324</th>\n",
              "      <td>images/n02172182/n02172182_9821.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63325 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       image  class\n",
              "0      images/n02111277/n02111277_10005.JPEG      0\n",
              "1      images/n02111277/n02111277_10019.JPEG      0\n",
              "2      images/n02111277/n02111277_10072.JPEG      0\n",
              "3       images/n02111277/n02111277_1008.JPEG      0\n",
              "4      images/n02111277/n02111277_10089.JPEG      0\n",
              "...                                      ...    ...\n",
              "63320   images/n02172182/n02172182_9515.JPEG     49\n",
              "63321    images/n02172182/n02172182_954.JPEG     49\n",
              "63322   images/n02172182/n02172182_9549.JPEG     49\n",
              "63323   images/n02172182/n02172182_9589.JPEG     49\n",
              "63324   images/n02172182/n02172182_9821.JPEG     49\n",
              "\n",
              "[63325 rows x 2 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set = train_set.rename(columns = {0:\"image\", 1:\"class\"})\n",
        "train_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "oNx-b7Eu4W0i",
        "outputId": "10983c9b-be8e-4e26-978f-4f0e297c153c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>images/n02111277/n02111277_9695.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>images/n02111277/n02111277_9747.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>images/n02111277/n02111277_975.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>images/n02111277/n02111277_9795.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>images/n02111277/n02111277_980.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>images/n02172182/n02172182_993.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>images/n02172182/n02172182_9953.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>images/n02172182/n02172182_997.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>images/n02172182/n02172182_998.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>images/n02172182/n02172182_9982.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>450 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    image  class\n",
              "0    images/n02111277/n02111277_9695.JPEG      0\n",
              "1    images/n02111277/n02111277_9747.JPEG      0\n",
              "2     images/n02111277/n02111277_975.JPEG      0\n",
              "3    images/n02111277/n02111277_9795.JPEG      0\n",
              "4     images/n02111277/n02111277_980.JPEG      0\n",
              "..                                    ...    ...\n",
              "445   images/n02172182/n02172182_993.JPEG     49\n",
              "446  images/n02172182/n02172182_9953.JPEG     49\n",
              "447   images/n02172182/n02172182_997.JPEG     49\n",
              "448   images/n02172182/n02172182_998.JPEG     49\n",
              "449  images/n02172182/n02172182_9982.JPEG     49\n",
              "\n",
              "[450 rows x 2 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_set = valid_set.rename(columns = {0:\"image\", 1:\"class\"})\n",
        "valid_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "06HqVcCS4aJS",
        "outputId": "3a16748f-62ba-47d8-a30f-0bec2d0fd08f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>images/n02111277/n02111277_9420.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>images/n02111277/n02111277_9422.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>images/n02111277/n02111277_9484.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>images/n02111277/n02111277_951.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>images/n02111277/n02111277_9518.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>images/n02172182/n02172182_974.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>images/n02172182/n02172182_9765.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>images/n02172182/n02172182_9789.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>images/n02172182/n02172182_98.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>images/n02172182/n02172182_981.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>450 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    image  class\n",
              "0    images/n02111277/n02111277_9420.JPEG      0\n",
              "1    images/n02111277/n02111277_9422.JPEG      0\n",
              "2    images/n02111277/n02111277_9484.JPEG      0\n",
              "3     images/n02111277/n02111277_951.JPEG      0\n",
              "4    images/n02111277/n02111277_9518.JPEG      0\n",
              "..                                    ...    ...\n",
              "445   images/n02172182/n02172182_974.JPEG     49\n",
              "446  images/n02172182/n02172182_9765.JPEG     49\n",
              "447  images/n02172182/n02172182_9789.JPEG     49\n",
              "448    images/n02172182/n02172182_98.JPEG     49\n",
              "449   images/n02172182/n02172182_981.JPEG     49\n",
              "\n",
              "[450 rows x 2 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set = test_set.rename(columns = {0:\"image\", 1:\"class\"})\n",
        "test_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0zPcXEBg4fC3"
      },
      "outputs": [],
      "source": [
        "train_img = []\n",
        "for i in range(len(train_set[\"image\"])):\n",
        "    temp = cv2.imread(\"images/\"+train_set[\"image\"][i])\n",
        "    temp = cv2.resize(temp, (128, 128))\n",
        "    train_img.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "U8EdFcgv4kYQ"
      },
      "outputs": [],
      "source": [
        "valid_img = []\n",
        "for i in range(len(valid_set[\"image\"])):\n",
        "    temp = cv2.imread(\"images/\"+valid_set[\"image\"][i])\n",
        "    temp = cv2.resize(temp, (128, 128))\n",
        "    valid_img.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_ZD4ICk34pyh"
      },
      "outputs": [],
      "source": [
        "test_img = []\n",
        "for i in range(len(test_set[\"image\"])):\n",
        "    temp = cv2.imread(\"images/\"+test_set[\"image\"][i])\n",
        "    temp = cv2.resize(temp, (128, 128))\n",
        "    test_img.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_img = np.array(train_img)\n",
        "valid_img = np.array(valid_img)\n",
        "test_img = np.array(test_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = torch.from_numpy(train_img)\n",
        "x_valid = torch.from_numpy(valid_img)\n",
        "x_test = torch.from_numpy(test_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = x_train.permute(0,3,1,2)\n",
        "x_valid = x_valid.permute(0,3,1,2)\n",
        "x_test = x_test.permute(0,3,1,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "O9XIHSnK4scG"
      },
      "outputs": [],
      "source": [
        "y_train = train_set[\"class\"]\n",
        "y_valid = valid_set[\"class\"]\n",
        "y_test = test_set[\"class\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "W8O0iIjN55AU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RRDB(nn.Module):\n",
        "    def __init__(self, in_channels, growth_channels):\n",
        "        super(RRDB, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, growth_channels, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(growth_channels, growth_channels, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(growth_channels, growth_channels, kernel_size=3, padding=1)\n",
        "        #self.conv4 = nn.Conv2d(growth_channels, growth_channels, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(growth_channels, in_channels, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = F.leaky_relu(self.conv1(x))\n",
        "        out = F.leaky_relu(self.conv2(out))\n",
        "        out = F.leaky_relu(self.conv3(out))\n",
        "        #out = F.leaky_relu(self.conv4(out))\n",
        "        out = self.conv5(out)\n",
        "        return residual + out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Classification(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(Classification, self).__init__()\n",
        "        self.rrdb1 = RRDB(in_channels, 64)\n",
        "        self.rrdb2 = RRDB(in_channels, 64)\n",
        "        self.rrdb3 = RRDB(in_channels, 64)\n",
        "        #self.rrdb4 = RRDB(in_channels, 64)  # å¢žåŠ ä¸€å€‹RRDB\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(in_channels, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.rrdb1(x)\n",
        "        x = self.rrdb2(x)\n",
        "        x = self.rrdb3(x)\n",
        "        #x = self.rrdb4(x)  # å¢žåŠ forward pass\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification(\n",
            "  (rrdb1): RRDB(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv5): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (rrdb2): RRDB(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv5): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (rrdb3): RRDB(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv5): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (pool): AdaptiveAvgPool2d(output_size=1)\n",
            "  (fc): Linear(in_features=3, out_features=50, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Model initialization\n",
        "numclasses = 50\n",
        "model = Classification(in_channels=3, num_classes=numclasses)  # Example for RGB images and 10 classes\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "weight_decay = 1e-4\n",
        "epochs = 20\n",
        "batch_size = 128\n",
        "valid_batch_size = 20\n",
        "test_batch_size = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "# loader = DataLoader(list(zip(X_train, y_train)), shuffle=True, batch_size=16)\n",
        "trainloader = torch.utils.data.DataLoader(list(zip(x_train, y_train)), batch_size=batch_size, shuffle=True)\n",
        "validloader = torch.utils.data.DataLoader(list(zip(x_valid, y_valid)), batch_size=valid_batch_size, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(list(zip(x_test, y_test)), batch_size=test_batch_size, shuffle=False)\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    avg_loss = 0.\n",
        "    train_acc = 0.\n",
        "    lr = 0.001\n",
        "    for batch_idx, (data, target) in enumerate(trainloader):\n",
        "\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data.to(torch.float32))\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        avg_loss += loss.item()\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "    print('Train Epoch: {}, loss{:.6f}, acc{}'.format(epoch, loss.item(), train_acc/len(trainloader.dataset)), end='')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validation(epoch):\n",
        "    model.eval()\n",
        "    valid_loss = 0.\n",
        "    correct=0.\n",
        "    with torch.no_grad():\n",
        "        for data, label in validloader:\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            output = model(data.to(torch.float32))\n",
        "            valid_loss += F.cross_entropy(output, label, size_average=False).item()\n",
        "            pred =  output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
        "    valid_loss/=len(validloader.dataset)\n",
        "    correct = int(correct)\n",
        "    print('Test set:average loss: {:.4f}, accuracy{}'.format(valid_loss, correct/len(validloader.dataset)))\n",
        "    return correct/len(validloader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1, loss3.952657, acc0.020497433841228485"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set:average loss: 3.9350, accuracy0.015555555555555555\n",
            "Train Epoch: 2, loss3.927357, acc0.021776549518108368Test set:average loss: 3.8980, accuracy0.02666666666666667\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "best_val_acc=0.\n",
        "val_acc = []\n",
        "for i in range(epochs):\n",
        "    train(i+1)\n",
        "    temp_acc = validation(i+1)\n",
        "    val_acc.append(temp_acc)\n",
        "    if temp_acc > best_val_acc:\n",
        "        best_val_acc = temp_acc\n",
        "print('Best acc{}'.format(best_val_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0.\n",
        "    correct=0.\n",
        "    with torch.no_grad():\n",
        "        for data, label in testloader:\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            output = model(data.to(torch.float32))\n",
        "            test_loss += F.cross_entropy(output, label, size_average=False).item()\n",
        "            pred =  output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
        "    test_loss/=len(testloader.dataset)\n",
        "    correct = int(correct)\n",
        "    print('Test set:average loss: {:.4f}, accuracy{}'.format(test_loss, 100.*correct/len(testloader.dataset)))\n",
        "    return correct/len(testloader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "\n",
        "model_resnet34 = models.resnet34(pretrained = False)\n",
        "num_feature = model_resnet34.fc.in_features\n",
        "model_resnet34.fc = torch.nn.Linear(num_feature, numclasses)\n",
        "model_resnet34.to(device)\n",
        "optimizer_resnet = optim.Adam(model_resnet34.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_resnet(epoch):\n",
        "    model_resnet34.train()\n",
        "    avg_loss = 0.\n",
        "    train_acc = 0.\n",
        "    for batch_idx, (data, target) in enumerate(trainloader):\n",
        "\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer_resnet.zero_grad()\n",
        "        output = model_resnet34(data.to(torch.float32))\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        avg_loss += loss.item()\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer_resnet.step()\n",
        "    print('Train Epoch: {}, loss{:.6f}, acc{}'.format(epoch, loss.item(), train_acc/len(trainloader.dataset)), end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validation_resnet(epoch):\n",
        "    model_resnet34.eval()\n",
        "    valid_loss = 0.\n",
        "    correct=0.\n",
        "    with torch.no_grad():\n",
        "        for data, label in validloader:\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            output = model_resnet34(data.to(torch.float32))\n",
        "            valid_loss += F.cross_entropy(output, label, size_average=False).item()\n",
        "            pred =  output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
        "    valid_loss/=len(validloader.dataset)\n",
        "    correct = int(correct)\n",
        "    print('Valid set:average loss: {:.4f}, accuracy{}'.format(valid_loss, correct/len(validloader.dataset)))\n",
        "    return correct/len(validloader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1, loss2.731509, acc0.1607264131307602"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid set:average loss: 3.0240, accuracy0.19555555555555557\n",
            "Train Epoch: 2, loss2.273692, acc0.2793525457382202Valid set:average loss: 2.8202, accuracy0.19777777777777777\n",
            "Train Epoch: 3, loss2.193475, acc0.36268457770347595Valid set:average loss: 2.2272, accuracy0.34\n",
            "Train Epoch: 4, loss1.936304, acc0.4371733069419861Valid set:average loss: 3.0605, accuracy0.28888888888888886\n",
            "Train Epoch: 5, loss1.374545, acc0.5000710487365723Valid set:average loss: 2.0628, accuracy0.4177777777777778\n"
          ]
        }
      ],
      "source": [
        "best_val_acc_34=0.\n",
        "val_acc_34 = []\n",
        "for i in range(epochs):\n",
        "    train_resnet(i+1)\n",
        "    temp_acc = validation_resnet(i+1)\n",
        "    val_acc_34.append(temp_acc)\n",
        "    if temp_acc > best_val_acc_34:\n",
        "        best_val_acc_34 = temp_acc\n",
        "print('Best acc{}'.format(best_val_acc_34))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_resnet():\n",
        "    model_resnet34.eval()\n",
        "    test_loss = 0.\n",
        "    correct=0.\n",
        "    with torch.no_grad():\n",
        "        for data, label in testloader:\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            output = model_resnet34(data.to(torch.float32))\n",
        "            test_loss += F.cross_entropy(output, label, size_average=False).item()\n",
        "            pred =  output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
        "    test_loss/=len(testloader.dataset)\n",
        "    correct = int(correct)\n",
        "    print('Test set:average loss: {:.4f}, accuracy{}'.format(test_loss, 100.*correct/len(testloader.dataset)))\n",
        "    return correct/len(testloader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_resnet()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
