{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNq4rf7s5B85",
        "outputId": "c1088a39-a96b-4b1a-e456-47ea6015721c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebV1GKSC5n7A",
        "outputId": "3eb98e9e-c12e-4648-fd27-bb063cc4061a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/112_2_DL\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['Assignment2_Q1.ipynb', 'images', 'Assignment2_Q2.ipynb']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/112_2_DL\"\n",
        "import os\n",
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4cao3gwe6iw0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vZiYIlWn8QHK"
      },
      "outputs": [],
      "source": [
        "train_set = pd.read_csv(\"images/train.txt\", sep=\" \", header=None)\n",
        "valid_set = pd.read_csv(\"images/val.txt\", sep=\" \", header=None)\n",
        "test_set = pd.read_csv(\"images/test.txt\", sep=\" \", header = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "JUStz5kO_P1v",
        "outputId": "b7f32bc1-fd89-4746-85dc-f3c7b600ffa4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>images/n02111277/n02111277_10005.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>images/n02111277/n02111277_10019.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>images/n02111277/n02111277_10072.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>images/n02111277/n02111277_1008.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>images/n02111277/n02111277_10089.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63320</th>\n",
              "      <td>images/n02172182/n02172182_9515.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63321</th>\n",
              "      <td>images/n02172182/n02172182_954.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63322</th>\n",
              "      <td>images/n02172182/n02172182_9549.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63323</th>\n",
              "      <td>images/n02172182/n02172182_9589.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63324</th>\n",
              "      <td>images/n02172182/n02172182_9821.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63325 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       image  class\n",
              "0      images/n02111277/n02111277_10005.JPEG      0\n",
              "1      images/n02111277/n02111277_10019.JPEG      0\n",
              "2      images/n02111277/n02111277_10072.JPEG      0\n",
              "3       images/n02111277/n02111277_1008.JPEG      0\n",
              "4      images/n02111277/n02111277_10089.JPEG      0\n",
              "...                                      ...    ...\n",
              "63320   images/n02172182/n02172182_9515.JPEG     49\n",
              "63321    images/n02172182/n02172182_954.JPEG     49\n",
              "63322   images/n02172182/n02172182_9549.JPEG     49\n",
              "63323   images/n02172182/n02172182_9589.JPEG     49\n",
              "63324   images/n02172182/n02172182_9821.JPEG     49\n",
              "\n",
              "[63325 rows x 2 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set = train_set.rename(columns = {0:\"image\", 1:\"class\"})\n",
        "train_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Qt5VCRaP_SbD",
        "outputId": "b0dfce95-5dd2-4bf3-93c4-ee055d4d45e8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>images/n02111277/n02111277_9695.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>images/n02111277/n02111277_9747.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>images/n02111277/n02111277_975.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>images/n02111277/n02111277_9795.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>images/n02111277/n02111277_980.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>images/n02172182/n02172182_993.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>images/n02172182/n02172182_9953.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>images/n02172182/n02172182_997.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>images/n02172182/n02172182_998.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>images/n02172182/n02172182_9982.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>450 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    image  class\n",
              "0    images/n02111277/n02111277_9695.JPEG      0\n",
              "1    images/n02111277/n02111277_9747.JPEG      0\n",
              "2     images/n02111277/n02111277_975.JPEG      0\n",
              "3    images/n02111277/n02111277_9795.JPEG      0\n",
              "4     images/n02111277/n02111277_980.JPEG      0\n",
              "..                                    ...    ...\n",
              "445   images/n02172182/n02172182_993.JPEG     49\n",
              "446  images/n02172182/n02172182_9953.JPEG     49\n",
              "447   images/n02172182/n02172182_997.JPEG     49\n",
              "448   images/n02172182/n02172182_998.JPEG     49\n",
              "449  images/n02172182/n02172182_9982.JPEG     49\n",
              "\n",
              "[450 rows x 2 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_set = valid_set.rename(columns = {0:\"image\", 1:\"class\"})\n",
        "valid_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "yUFlz8Z7_WrM",
        "outputId": "60a59c61-f4f6-41a9-afab-3056f241fd01"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>images/n02111277/n02111277_9420.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>images/n02111277/n02111277_9422.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>images/n02111277/n02111277_9484.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>images/n02111277/n02111277_951.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>images/n02111277/n02111277_9518.JPEG</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>images/n02172182/n02172182_974.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>images/n02172182/n02172182_9765.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>images/n02172182/n02172182_9789.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>images/n02172182/n02172182_98.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>images/n02172182/n02172182_981.JPEG</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>450 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    image  class\n",
              "0    images/n02111277/n02111277_9420.JPEG      0\n",
              "1    images/n02111277/n02111277_9422.JPEG      0\n",
              "2    images/n02111277/n02111277_9484.JPEG      0\n",
              "3     images/n02111277/n02111277_951.JPEG      0\n",
              "4    images/n02111277/n02111277_9518.JPEG      0\n",
              "..                                    ...    ...\n",
              "445   images/n02172182/n02172182_974.JPEG     49\n",
              "446  images/n02172182/n02172182_9765.JPEG     49\n",
              "447  images/n02172182/n02172182_9789.JPEG     49\n",
              "448    images/n02172182/n02172182_98.JPEG     49\n",
              "449   images/n02172182/n02172182_981.JPEG     49\n",
              "\n",
              "[450 rows x 2 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set = test_set.rename(columns = {0:\"image\", 1:\"class\"})\n",
        "test_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7HN0Wg1T_cRS"
      },
      "outputs": [],
      "source": [
        "train_img = []\n",
        "for i in range(len(train_set[\"image\"])):\n",
        "    temp = cv2.imread(\"images/\"+train_set[\"image\"][i])\n",
        "    temp = cv2.resize(temp, (128, 128))\n",
        "    train_img.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5Khmq7if5JFJ"
      },
      "outputs": [],
      "source": [
        "valid_img = []\n",
        "for i in range(len(valid_set[\"image\"])):\n",
        "    temp = cv2.imread(\"images/\"+valid_set[\"image\"][i])\n",
        "    temp = cv2.resize(temp, (128, 128))\n",
        "    valid_img.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OMbS7Ayd5PQD"
      },
      "outputs": [],
      "source": [
        "test_img = []\n",
        "for i in range(len(test_set[\"image\"])):\n",
        "    temp = cv2.imread(\"images/\"+test_set[\"image\"][i])\n",
        "    temp = cv2.resize(temp, (128, 128))\n",
        "    test_img.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NPyCC4DYVxSv"
      },
      "outputs": [],
      "source": [
        "train_img = np.array(train_img)\n",
        "valid_img = np.array(valid_img)\n",
        "test_img = np.array(test_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = torch.from_numpy(train_img)\n",
        "x_valid = torch.from_numpy(valid_img)\n",
        "x_test = torch.from_numpy(test_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = x_train.permute(0,3,1,2)\n",
        "x_valid = x_valid.permute(0,3,1,2)\n",
        "x_test = x_test.permute(0,3,1,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "l92rjJncVxZH",
        "outputId": "72fe9d54-3d7d-4b53-c69a-965605e456a9"
      },
      "outputs": [],
      "source": [
        "y_train = train_set[\"class\"]\n",
        "y_valid = valid_set[\"class\"]\n",
        "y_test = test_set[\"class\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "viSCYC6-5oYs"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "EcrogUMWFTtS"
      },
      "outputs": [],
      "source": [
        "class attention2d(nn.Module):\n",
        "    def __init__(self, in_planes, ratios, K, temperature, init_weight=True):\n",
        "        super(attention2d, self).__init__()\n",
        "        assert temperature%3==1\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        if in_planes!=3:\n",
        "            hidden_planes = int(in_planes*ratios)+1\n",
        "        else:\n",
        "            hidden_planes = K\n",
        "        self.fc1 = nn.Conv2d(in_planes, hidden_planes, 1, bias=False)\n",
        "        # self.bn = nn.BatchNorm2d(hidden_planes)\n",
        "        self.fc2 = nn.Conv2d(hidden_planes, K, 1, bias=True)\n",
        "        self.temperature = temperature\n",
        "        if init_weight:\n",
        "            self._initialize_weights()\n",
        "\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            if isinstance(m ,nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def updata_temperature(self):\n",
        "        if self.temperature!=1:\n",
        "            self.temperature -=3\n",
        "            #print('Change temperature to:', str(self.temperature))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.avgpool(x)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x).view(x.size(0), -1)\n",
        "        return F.softmax(x/self.temperature, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "x6-djhzRFrTP"
      },
      "outputs": [],
      "source": [
        "class Dynamic_conv2d(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size, ratio=0.25, stride=1, padding=0, dilation=1, groups=1, bias=True, K=4,temperature=34, init_weight=True):\n",
        "        super(Dynamic_conv2d, self).__init__()\n",
        "        assert in_planes%groups==0\n",
        "        self.in_planes = in_planes\n",
        "        self.out_planes = out_planes\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "        self.groups = groups\n",
        "        self.bias = bias\n",
        "        self.K = K\n",
        "        self.attention = attention2d(in_planes, ratio, K, temperature)\n",
        "\n",
        "        self.weight = nn.Parameter(torch.randn(K, out_planes, in_planes//groups, kernel_size, kernel_size), requires_grad=True)\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.zeros(K, out_planes))\n",
        "        else:\n",
        "            self.bias = None\n",
        "        if init_weight:\n",
        "            self._initialize_weights()\n",
        "\n",
        "        #TODO 初始化\n",
        "    def _initialize_weights(self):\n",
        "        for i in range(self.K):\n",
        "            nn.init.kaiming_uniform_(self.weight[i])\n",
        "\n",
        "\n",
        "    def update_temperature(self):\n",
        "        self.attention.updata_temperature()\n",
        "\n",
        "    def forward(self, x):#将batch视作维度变量，进行组卷积，因为组卷积的权重是不同的，动态卷积的权重也是不同的\n",
        "        softmax_attention = self.attention(x)\n",
        "        batch_size, in_planes, height, width = x.size()\n",
        "        x = x.view(1, -1, height, width)# 变化成一个维度进行组卷积\n",
        "        weight = self.weight.view(self.K, -1)\n",
        "\n",
        "        # 动态卷积的权重的生成， 生成的是batch_size个卷积参数（每个参数不同）\n",
        "        aggregate_weight = torch.mm(softmax_attention, weight).view(batch_size*self.out_planes, self.in_planes//self.groups, self.kernel_size, self.kernel_size)\n",
        "        if self.bias is not None:\n",
        "            aggregate_bias = torch.mm(softmax_attention, self.bias).view(-1)\n",
        "            output = F.conv2d(x, weight=aggregate_weight, bias=aggregate_bias, stride=self.stride, padding=self.padding,\n",
        "                              dilation=self.dilation, groups=self.groups*batch_size)\n",
        "        else:\n",
        "            output = F.conv2d(x, weight=aggregate_weight, bias=None, stride=self.stride, padding=self.padding,\n",
        "                              dilation=self.dilation, groups=self.groups * batch_size)\n",
        "\n",
        "        output = output.view(batch_size, self.out_planes, output.size(-2), output.size(-1))\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "skFtgRrYF7nK"
      },
      "outputs": [],
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    return Dynamic_conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=dilation, groups=groups, bias=False, dilation=dilation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "E7ExkFCqGt2B"
      },
      "outputs": [],
      "source": [
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    return Dynamic_conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DuBRs2fOGyvj"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    __constants__ = ['downsample']\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "cHaTIbC2HV6o"
      },
      "outputs": [],
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    __constants__ = ['downsample']\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4lt3emJUHywB"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=50, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def update_temperature(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, Dynamic_conv2d):\n",
        "                m.update_temperature()\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZV5F6SO_Ik20"
      },
      "outputs": [],
      "source": [
        "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0vHkUKMvIsbs"
      },
      "outputs": [],
      "source": [
        "def dy_resnet18(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
        "                   **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2Pg-lifnJbyM"
      },
      "outputs": [],
      "source": [
        "from torchvision.models.resnet import resnet18 as raw_resnet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "GShwmqiEJCqh"
      },
      "outputs": [],
      "source": [
        "numclasses = 50\n",
        "model = dy_resnet18(num_classes=numclasses)\n",
        "net_name = \"dy_resnet18\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcLFqNt1MCbV"
      },
      "source": [
        "import argparse\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(description='dynamic convolution')\n",
        "\n",
        "parser.add_argument('--dataset', type=str, default='mini-ImageNet', help='training dataset')\n",
        "\n",
        "parser.add_argument('--batch-size', type=int, default=128)\n",
        "\n",
        "parser.add_argument('--test-batch-size', type=int, default=20)\n",
        "\n",
        "parser.add_argument('--epochs', type=int, default=160)\n",
        "\n",
        "parser.add_argument('--lr', type=float, default=0.1, )\n",
        "\n",
        "parser.add_argument('--momentum', type=float, default=0.9)\n",
        "\n",
        "parser.add_argument('--weight-decay', type=float, default=1e-4)\n",
        "\n",
        "parser.add_argument('--net-name', default='dy_resnet18')\n",
        "\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "args.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "37t84bxEMzvw"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "weight_decay = 1e-4\n",
        "epochs = 30\n",
        "batch_size = 128\n",
        "valid_batch_size = 20\n",
        "test_batch_size = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "JJL3HgkGLcI8"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "# loader = DataLoader(list(zip(X_train, y_train)), shuffle=True, batch_size=16)\n",
        "trainloader = torch.utils.data.DataLoader(list(zip(x_train, y_train)), batch_size=batch_size, shuffle=True)\n",
        "validloader = torch.utils.data.DataLoader(list(zip(x_valid, y_valid)), batch_size=valid_batch_size, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(list(zip(x_test, y_test)), batch_size=test_batch_size, shuffle=False)\n",
        "model.to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xoNBdMXeMw5B"
      },
      "outputs": [],
      "source": [
        "def adjust_lr(optimizer, epoch):\n",
        "    if epoch in [epochs*0.5, epochs*0.75, epochs*0.85]:\n",
        "        for p in optimizer.param_groups:\n",
        "            p['lr'] *= 0.1\n",
        "            lr = p['lr']\n",
        "        #print('Change lr:'+str(lr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "LRIw_ekaNUI3"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    avg_loss = 0.\n",
        "    train_acc = 0.\n",
        "    adjust_lr(optimizer, epoch)\n",
        "    for batch_idx, (data, target) in enumerate(trainloader):\n",
        "\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data.to(torch.float32))\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        avg_loss += loss.item()\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "    print('Train Epoch: {}, loss{:.6f}, acc{}'.format(epoch, loss.item(), train_acc/len(trainloader.dataset)), end='')\n",
        "    if net_name.startswith('dy'):\n",
        "        model.update_temperature()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "fQtMnC3MRWZI"
      },
      "outputs": [],
      "source": [
        "def validation(epoch):\n",
        "    model.eval()\n",
        "    valid_loss = 0.\n",
        "    correct=0.\n",
        "    with torch.no_grad():\n",
        "        for data, label in validloader:\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            output = model(data.to(torch.float32))\n",
        "            valid_loss += F.cross_entropy(output, label, size_average=False).item()\n",
        "            pred =  output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
        "    valid_loss/=len(validloader.dataset)\n",
        "    correct = int(correct)\n",
        "    print('Valid set:average loss: {:.4f}, accuracy{}'.format(valid_loss, correct/len(validloader.dataset)))\n",
        "    return correct/len(validloader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "z6TXCfHbR8Un",
        "outputId": "b64a7609-3b25-4037-8beb-63232fc14467"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1, loss3.496431, acc0.07297275960445404"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid set:average loss: 3.5395, accuracy0.10222222222222223\n",
            "Train Epoch: 2, loss3.042214, acc0.14525069296360016Valid set:average loss: 3.4573, accuracy0.12444444444444444\n",
            "Train Epoch: 3, loss3.042984, acc0.18869325518608093Valid set:average loss: 3.4093, accuracy0.14\n",
            "Train Epoch: 4, loss2.613018, acc0.22160284221172333Valid set:average loss: 3.1174, accuracy0.1711111111111111\n",
            "Train Epoch: 5, loss2.686348, acc0.2497749775648117Valid set:average loss: 3.0819, accuracy0.17777777777777778\n",
            "Train Epoch: 6, loss2.675732, acc0.2753888666629791Valid set:average loss: 2.6110, accuracy0.25555555555555554\n",
            "Train Epoch: 7, loss2.685779, acc0.3032451570034027Valid set:average loss: 2.8486, accuracy0.23777777777777778\n",
            "Train Epoch: 8, loss2.596398, acc0.32669562101364136Valid set:average loss: 3.1939, accuracy0.21555555555555556\n",
            "Train Epoch: 9, loss2.440928, acc0.3447927236557007Valid set:average loss: 4.9922, accuracy0.17555555555555555\n",
            "Train Epoch: 10, loss2.362315, acc0.2915436327457428Valid set:average loss: 14.6928, accuracy0.044444444444444446\n",
            "Train Epoch: 11, loss2.945125, acc0.12009474635124207Valid set:average loss: 15.6062, accuracy0.022222222222222223\n",
            "Train Epoch: 12, loss3.922512, acc0.04124753177165985Valid set:average loss: 3.8651, accuracy0.042222222222222223\n",
            "Train Epoch: 13, loss3.820643, acc0.057323332875967026Valid set:average loss: 3.9115, accuracy0.024444444444444446\n",
            "Train Epoch: 14, loss3.491374, acc0.057197000831365585Valid set:average loss: 3.6443, accuracy0.07111111111111111\n",
            "Train Epoch: 15, loss3.523327, acc0.08282668888568878Valid set:average loss: 3.5798, accuracy0.1\n",
            "Train Epoch: 16, loss3.448504, acc0.08514804393053055Valid set:average loss: 3.5723, accuracy0.09777777777777778\n",
            "Train Epoch: 17, loss3.492752, acc0.09441768378019333Valid set:average loss: 3.5394, accuracy0.10888888888888888\n",
            "Train Epoch: 18, loss3.440464, acc0.09833399206399918Valid set:average loss: 3.5169, accuracy0.1111111111111111\n",
            "Train Epoch: 19, loss3.473829, acc0.10030793398618698Valid set:average loss: 3.5190, accuracy0.10222222222222223\n",
            "Train Epoch: 20, loss3.377985, acc0.10564547777175903Valid set:average loss: 3.4904, accuracy0.10888888888888888\n",
            "Train Epoch: 21, loss3.580830, acc0.10911962389945984Valid set:average loss: 3.4691, accuracy0.10666666666666667\n",
            "Train Epoch: 22, loss3.666778, acc0.09154362231492996Valid set:average loss: 3.6352, accuracy0.06666666666666667\n",
            "Train Epoch: 23, loss3.316215, acc0.08565337210893631Valid set:average loss: 3.5165, accuracy0.10222222222222223\n",
            "Train Epoch: 24, loss3.386168, acc0.10049743205308914Valid set:average loss: 3.4474, accuracy0.10888888888888888\n",
            "Train Epoch: 25, loss3.612937, acc0.09912356734275818Valid set:average loss: 3.4348, accuracy0.09777777777777778\n",
            "Train Epoch: 26, loss3.585856, acc0.10817212611436844Valid set:average loss: 3.3961, accuracy0.11555555555555555\n",
            "Train Epoch: 27, loss3.433133, acc0.11448875069618225Valid set:average loss: 3.3767, accuracy0.11777777777777777\n",
            "Train Epoch: 28, loss3.320030, acc0.12064745277166367Valid set:average loss: 3.3407, accuracy0.14\n",
            "Train Epoch: 29, loss3.297379, acc0.12866955995559692Valid set:average loss: 3.3154, accuracy0.12\n",
            "Train Epoch: 30, loss3.222666, acc0.13467034697532654Valid set:average loss: 3.2840, accuracy0.13555555555555557\n",
            "Best acc0.25555555555555554\n"
          ]
        }
      ],
      "source": [
        "best_val_acc=0.\n",
        "val_acc = []\n",
        "for i in range(epochs):\n",
        "    train(i+1)\n",
        "    temp_acc = validation(i+1)\n",
        "    val_acc.append(temp_acc)\n",
        "    if temp_acc > best_val_acc:\n",
        "        best_val_acc = temp_acc\n",
        "print('Best acc{}'.format(best_val_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0.\n",
        "    correct=0.\n",
        "    with torch.no_grad():\n",
        "        for data, label in testloader:\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            output = model(data.to(torch.float32))\n",
        "            test_loss += F.cross_entropy(output, label, size_average=False).item()\n",
        "            pred =  output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
        "    test_loss/=len(testloader.dataset)\n",
        "    correct = int(correct)\n",
        "    print('Test set:average loss: {:.4f}, accuracy{}'.format(test_loss, 100.*correct/len(testloader.dataset)))\n",
        "    return correct/len(testloader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set:average loss: 3.2924, accuracy17.11111111111111\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.1711111111111111"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "\n",
        "model_resnet18 = models.resnet18(pretrained = False)\n",
        "num_feature = model_resnet18.fc.in_features\n",
        "model_resnet18.fc = torch.nn.Linear(num_feature, numclasses)\n",
        "model_resnet18.to(device)\n",
        "optimizer_resnet = optim.SGD(model_resnet18.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_resnet(epoch):\n",
        "    model_resnet18.train()\n",
        "    avg_loss = 0.\n",
        "    train_acc = 0.\n",
        "    adjust_lr(optimizer_resnet, epoch)\n",
        "    for batch_idx, (data, target) in enumerate(trainloader):\n",
        "\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer_resnet.zero_grad()\n",
        "        output = model_resnet18(data.to(torch.float32))\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        avg_loss += loss.item()\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer_resnet.step()\n",
        "    print('Train Epoch: {}, loss{:.6f}, acc{}'.format(epoch, loss.item(), train_acc/len(trainloader.dataset)), end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validation_resnet(epoch):\n",
        "    model_resnet18.eval()\n",
        "    valid_loss = 0.\n",
        "    correct=0.\n",
        "    with torch.no_grad():\n",
        "        for data, label in validloader:\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            output = model_resnet18(data.to(torch.float32))\n",
        "            valid_loss += F.cross_entropy(output, label, size_average=False).item()\n",
        "            pred =  output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
        "    valid_loss/=len(validloader.dataset)\n",
        "    correct = int(correct)\n",
        "    print('Valid set:average loss: {:.4f}, accuracy{}'.format(valid_loss, correct/len(validloader.dataset)))\n",
        "    return correct/len(validloader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1, loss3.331717, acc0.07848401367664337"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid set:average loss: 3.6017, accuracy0.10444444444444445\n",
            "Train Epoch: 2, loss3.092461, acc0.15172523260116577Valid set:average loss: 3.1083, accuracy0.2\n",
            "Train Epoch: 3, loss2.831559, acc0.19603632390499115Valid set:average loss: 3.0062, accuracy0.16444444444444445\n",
            "Train Epoch: 4, loss2.745202, acc0.23069877922534943Valid set:average loss: 2.8775, accuracy0.2111111111111111\n",
            "Train Epoch: 5, loss2.843068, acc0.26406633853912354Valid set:average loss: 2.7759, accuracy0.2111111111111111\n",
            "Train Epoch: 6, loss2.265332, acc0.2912119925022125Valid set:average loss: 3.3361, accuracy0.14666666666666667\n",
            "Train Epoch: 7, loss2.376279, acc0.3178681433200836Valid set:average loss: 2.6751, accuracy0.25333333333333335\n",
            "Train Epoch: 8, loss1.974718, acc0.3444611132144928Valid set:average loss: 2.6476, accuracy0.25555555555555554\n",
            "Train Epoch: 9, loss2.341848, acc0.36901697516441345Valid set:average loss: 3.2822, accuracy0.21333333333333335\n",
            "Train Epoch: 10, loss1.985300, acc0.39379391074180603Valid set:average loss: 2.6724, accuracy0.29333333333333333\n",
            "Train Epoch: 11, loss1.878681, acc0.41759178042411804Valid set:average loss: 2.7421, accuracy0.2688888888888889\n",
            "Train Epoch: 12, loss1.695652, acc0.4455428421497345Valid set:average loss: 2.3469, accuracy0.3333333333333333\n",
            "Train Epoch: 13, loss1.832728, acc0.47349387407302856Valid set:average loss: 2.4415, accuracy0.30666666666666664\n",
            "Train Epoch: 14, loss1.792236, acc0.5046032667160034Valid set:average loss: 2.5939, accuracy0.28888888888888886\n",
            "Train Epoch: 15, loss1.663459, acc0.5798973441123962Valid set:average loss: 2.1230, accuracy0.3844444444444444\n",
            "Train Epoch: 16, loss1.442941, acc0.5935412645339966Valid set:average loss: 2.1251, accuracy0.3933333333333333\n",
            "Train Epoch: 17, loss1.311091, acc0.6018633842468262Valid set:average loss: 2.1410, accuracy0.37777777777777777\n",
            "Train Epoch: 18, loss1.220056, acc0.607153594493866Valid set:average loss: 2.1161, accuracy0.36666666666666664\n",
            "Train Epoch: 19, loss1.332631, acc0.613312304019928Valid set:average loss: 2.1493, accuracy0.37333333333333335\n",
            "Train Epoch: 20, loss1.348857, acc0.620623767375946Valid set:average loss: 2.1574, accuracy0.38\n",
            "Train Epoch: 21, loss1.278315, acc0.6265929937362671Valid set:average loss: 2.2077, accuracy0.36666666666666664\n",
            "Train Epoch: 22, loss1.264526, acc0.633320152759552Valid set:average loss: 2.1673, accuracy0.38222222222222224\n",
            "Train Epoch: 23, loss1.453303, acc0.6409159302711487Valid set:average loss: 2.1594, accuracy0.38\n",
            "Train Epoch: 24, loss1.077157, acc0.6472641229629517Valid set:average loss: 2.1643, accuracy0.3711111111111111\n",
            "Train Epoch: 25, loss1.178792, acc0.6535175442695618Valid set:average loss: 2.1588, accuracy0.37555555555555553\n",
            "Train Epoch: 26, loss1.161473, acc0.6596446633338928Valid set:average loss: 2.1770, accuracy0.39111111111111113\n",
            "Train Epoch: 27, loss1.349475, acc0.6680616140365601Valid set:average loss: 2.1731, accuracy0.38222222222222224\n",
            "Train Epoch: 28, loss1.281750, acc0.6742518544197083Valid set:average loss: 2.1830, accuracy0.37333333333333335\n",
            "Train Epoch: 29, loss1.215734, acc0.680600106716156Valid set:average loss: 2.2026, accuracy0.37555555555555553\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "best_val_acc_18=0.\n",
        "val_acc_18 = []\n",
        "for i in range(epochs):\n",
        "    train_resnet(i+1)\n",
        "    temp_acc = validation_resnet(i+1)\n",
        "    val_acc_18.append(temp_acc)\n",
        "    if temp_acc > best_val_acc_18:\n",
        "        best_val_acc_18 = temp_acc\n",
        "print('Best acc{}'.format(best_val_acc_18))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_resnet():\n",
        "    model_resnet18.eval()\n",
        "    test_loss = 0.\n",
        "    correct=0.\n",
        "    with torch.no_grad():\n",
        "        for data, label in testloader:\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            output = model_resnet18(data.to(torch.float32))\n",
        "            test_loss += F.cross_entropy(output, label, size_average=False).item()\n",
        "            pred =  output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
        "    test_loss/=len(testloader.dataset)\n",
        "    correct = int(correct)\n",
        "    print('Test set:average loss: {:.4f}, accuracy{}'.format(test_loss, 100.*correct/len(testloader.dataset)))\n",
        "    return correct/len(testloader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_resnet()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
